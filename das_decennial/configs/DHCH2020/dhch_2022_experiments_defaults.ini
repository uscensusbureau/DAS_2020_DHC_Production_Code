[DEFAULT]
include=../default.ini

[alert]
message = Hello world!

[budget]
# In our 2022 DHC accuracy experiments, we actually used the rounded_continuous_gaussian_mechanism instead of the following, but this requires modifying programs/engine/primitives.py:
dp_mechanism = rounded_continuous_gaussian_mechanism
epsilon_budget_total =
geolevel_budget_prop =
global_scale =
only_dyadic_rationals = False
print_per_attr_epsilons = True
privacy_framework = zcdp
query_ordering = test_strategy_regular_ordering_dhch_20220217_omitRelative
strategy = test_strategy_dhch_20220217_OmitRelative

[constraints]
theConstraints.Block = h1, gq_vect, living_alone, size2, size3, size4, hh_elderly, age_child, owned
theConstraints.State = h1, gq_vect, living_alone, size2, size3, size4, hh_elderly, age_child, owned
theConstraints.US = h1, gq_vect, living_alone, size2, size3, size4, hh_elderly, age_child, owned
theInvariants.Block = tot, tot_hu, gqhh_vect

[engine]
aian_sum_constraints = False
check_budget = off
delete_raw = 0
engine = programs.engine.topdown_engine.TopdownEngine
geolevel_num_part = 1000000,100000,20000,2000,1000,400,40,1
postprocess_only = off
reload_noisy = 1
repartition_optimized_node_rdd_evenly = True
save_noisy = on
skip_persists_in_engine = True
part_size_noisy = 10
part_size_optimized = 10
part_size_optimized_block = 70

[environment]
aws_auto_scaling_home = /opt/aws/apitools/as
aws_cloudwatch_home = /opt/aws/apitools/mon
aws_elb_home = /opt/aws/apitools/elb
aws_path = /opt/aws
bcc_https_proxy = https://{HOST_NAME:PORT}
bcc_http_proxy = http://{HOST_NAME:PORT}
bcc_no_proxy = {IP_OR_HOST}
clusterid = j-3IP1RTLLN2Y45
# das_environment = ITE
das_framework_version = 0.0.1
das_loghost = {HOST_NAME} 
das_run_uuid = 37c12df1-6e79-48e5-b5f5-f3cdd10974cd
das_s3root = ${DAS_S3ROOT}
git_ssl_no_verify = true
grb_app_name = DAS
grb_env3 = 0
grb_env4 =
grb_isv_name = Census
grb_license_file = /usr/local/lib64/python3.6/site-packages/gurobipy/gurobi_client.lic
gurobi_home = /usr/local/lib64/python3.6/site-packages/gurobipy
temp = /usr/tmp
tmpdir = /usr/tmp
tz = America/New_York

[error_metrics]
calculate_binned_query_errors = False
error_metrics = programs.metrics.accuracy_metrics.AccuracyMetrics
print_place_mcd_ose_bg_l1_error_on_total_pop = True
queries2measure = hhsize_all, presence75, size1, presence65, dhch_hhtype_p12_part2 * sex, dhch_pco3_margin2, hisp, dhch_p16_margin, size1_size2plus, dhch_hhtype_p12_part1, dhch_pco3_margin3, coupled_hh_type, hhtenshort, dhch_pco3_margin1, race, dhch_hhtype_p12_part3 * sex, dhch_hhtype_hct3, multig, dhch_pco3_margin2 * sex, hhtype_dhch_married_fam_pco11_p1, sex * popSehsdTarget_upart, sex, hhage, presence60, multig * hisp * hhtenshort, partner_type_own_child_status * sex * hhtenshort, coupled_hh_type * hisp * hhtenshort
skip_levels = Block
compute_prim_error_metrics = True

[experiment]
experiment = programs.experiment.experiment.experiment
run_experiment_flag = 0

[geodict]
aian_areas = Legal_Federally_Recognized_American_Indian_Area,American_Indian_Joint_Use_Area,Hawaiian_Home_Land,Alaska_Native_Village_Statistical_Area,State_Recognized_Legal_American_Indian_Area,Oklahoma_Tribal_Statistical_Area,Joint_Use_Oklahoma_Tribal_Statistical_Area
geocode_length = 16
geolevel_leng = 16,13,12,11,6,5,2,0
geolevel_names =
geo_bottomlevel = Block
geo_path =
geo_toplevel =
prim_spine = True
spine = opt_spine
spine.re = ([a-z_]+)
spine.required = True
target_orig_block_groups= False
target_das_aian_areas=True

[gurobi]
barconvtol = 1e-10
bariterlimit = 1000
barqcpconvtol = 0
bhfdr = 0.1
constrain_main_vars_to_zero = True
dataindnpass_tolerancetype = opt_tol
feasibilitytol = 1e-8
gurobi_lic = /usr/local/lib64/python3.6/site-packages/gurobipy/gurobi_client.lic
gurobi_lic_create = true
gurobi_logfile_name = gurobi.log
gurobi_path = /usr/local/lib64/python3.6/site-packages/gurobipy/linux64/lib/python3.7_utf32/
heartbeat_frequency = 0
l2_acceptable_statuses = SUBOPTIMAL,ITERATION_LIMIT
l2_grb_algorithm = -1
l2_grb_presolve = -1
l2_grb_presparsify = -1
l2_optimization_approach = DataIndUserSpecifiedQueriesNPassDecomp
l2_suboptimal_allowed = False
maxtaildelta = 0.01
method = -1
mipfocus = 1
notification_frequency = 120
numericfocus = 3
optimalitytol = 1e-8
opt_tol_slack = 0.01
outputflag = 1
port = 41954
presolve = 2
print_gurobi_stats = False
python_presolve = 0
random_report_frequency = 0.0
record_gurobi_stats = True
rounder_acceptable_statuses = SUBOPTIMAL,ITERATION_LIMIT
rounder_optimization_approach = MultipassRounderDecomp
save_lp_seconds = 10000
seq_optimization_approach = L2PlusRounder_interleaved
skip_decomp = True
test_hist_decomp = False
threads = 4
threads_block = 3
threads_block_group = 4
threads_county = 16
threads_prim = 6
threads_root2root = 32
threads_state = 32
threads_tract = 4
threads_tract_subset = 4
threads_tract_subset_group = 4

[logging]
dvs_enabled = False
logfilename = DAS
logfolder = logs
loglevel = INFO

[monitoring]
heartbeat_frequency = 60
notification_frequency = 60
notify_dashboard_gurobi_retry = true
notify_dashboard_gurobi_success = false
print_heartbeat = False
print_heartbeat_frequency = 180
send_stacktrace = False

[reader]
comment = #
constraint_tables = h1
delimiter = |
elderly = p60 p65 p75
elderly.legal = 0-3
elderly.type = int
geocode.legal = 0000000000000000-9999999999999999
geocode.type = str
geocode_h1 = TABBLKST TABBLKCOU TABTRACTCE TABBLKGRPCE TABBLK
geocode_h1.legal = 0000000000000000-9999999999999999
geocode_h1.type = str
git_commit = das_framework commit 78c6c3b22a2145a8a79cd2238f449365b58ccbe4 |ctools commit c8982851d568b582e59633aa4034e10a2e8dacc0 |python_dvs commit abbc66f5d6bd39bfa6aebf8d3492d1e55ed3ae6d |das_decennial commit a15c58eb7858620ad3cac678d7cfba5649215aaa (untracked files present at run time)
gqtype.legal = 000-999
gqtype.type = str
grfc_path = ${DAS_S3INPUTS}/2010-convert/grfc/grfc_tab20_*.txt
h1.class = programs.reader.sql_spar_table.SQLSparseHistogramTable
h1.geography = geocode_h1
h1.histogram = HHSTATUS
h1.newrecoder = True

# Useful PL94 run paths for testing purposes (including those used in the 2022 DHC accuracy experiments):
# PATCHED COMFORT (US) (PL94)
# ${DAS_S3ROOT}/runs/tests/DAS-REL-019-litho-dsep-tuning-4/DAS-REL-019-litho-dsep-tuning-4/mdf/us/per/MDF10_PER_US.txt/MDF10_PER_US-MDFPL942020.txt
# PATCHED COMFORT trimmed to RI
# $DAS_S3ROOT/title13_PL94forDHCconstraints2010_data/ri_patched_comfort.txt
# FIRM_FRIEND (PR) (PL94)
# ${DAS_S3ROOT}/runs/tests/DAS-REL-019-litho-dsep-tuning-4/DAS-REL-019-litho-dsep-tuning-4/mdf/pr/per/MDF10_PER_PR.txt/MDF10_PER_PR-MDFPL942020.txt
# SALTY PICTURE (US) (H1)
# ${DAS_S3ROOT}/runs/tests/DAS-REL-019-ricin-dsep-tuning-1/DAS-REL-019-ricin-dsep-tuning-1/mdf/us/unit/MDF10_UNIT_US.txt/MDF10_UNIT_US-MDF2020H1.txt
# SALTY_PICTURE trimmed to RI
# $DAS_S3ROOT/title13_PL94forDHCconstraints2010_data/ri_salty_picture.txt
# CLANGING_FUNNY (PR) (H1)
# ${DAS_S3ROOT}/runs/tests/DAS-REL-019-ricin-dsep-tuning-1/DAS-REL-019-ricin-dsep-tuning-1/mdf/pr/unit/MDF10_UNIT_PR.txt/MDF10_UNIT_PR-MDF2020H1.txt

h1.path = ${DAS_S3INPUTS}/runs/tests/DAS-REL-019-ricin-dsep-tuning-1/mdf/us/unit/MDF10_UNIT_US.txt/MDF10_UNIT_US-MDF2020H1.txt
h1.recoder = programs.reader.from_mdf_recoder.DHCRecoder
h1.recode_variables = geocode_h1
h1.variables = SCHEMA_TYPE_CODE SCHEMA_BUILD_ID TABBLKST TABBLKCOU TABTRACTCE TABBLKGRPCE TABBLK RTYPE HHSTATUS
header = True
hhage = hhldrage
hhage.legal = 0-8
hhage.type = int
hhgq = gqtype vacs
hhgq.legal = 0-29
hhgq.type = int
hhstatus.legal = 0-2
hhstatus.type = str
hhtenshort = ten
hhtenshort.legal = 0-1
hhtenshort.type = int
hhtype.legal = 0-521
hhtype.type = int
hhtype_dhch = hht
hhtype_dhch.legal = 0-521
hhtype_dhch.type = int
hisp = hhspan
hisp.legal = 0-1
hisp.type = int
household.class = programs.reader.cef_2020.cef_2020_dhch_reader.CEF2020DHCHHouseholdTable
household.generated_module = programs.reader.cef_2020.cef_validator_classes
household.generated_table = CEF20_UNIT
household.geography = geocode
household.histogram = sex hhage hisp race elderly hhtenshort hhtype_dhch
household.path = ${DAS_S3INPUTS}/2010-convert/cef/us/unit
household.recoder = programs.reader.cef_2020.cef_2020_dhch_reader.DHCH_Household_recoder
household.recode_variables = sex hhage hisp race elderly hhtenshort hhtype_dhch
household.variables = mafid hisp sex ten geocode race elderly hhage hhtype
input_data_vintage = 2010
linkage = geocode
mafid.legal = 000000000-999999999
mafid.type = str
main_table = Household
numreaderpartitions = 1000
parts_after_reading = 1000000
privacy_table = Household
race = hhrace
race.legal = 0-6
race.type = int
reader = programs.reader.table_reader.DASDecennialReader
readerpartitionlen = 15
rtype.legal = 2,4
rtype.type = str
schema_build_id.legal = 0.0.0-9.9.9
schema_build_id.type = str
schema_type_code.legal = AAA-ZZZ
schema_type_code.type = str
sex = hhsex
sex.legal = 0-1
sex.type = int
skip_persist_in_reader = True
tabblk.legal = 0001-9999
tabblk.type = str
tabblkcou.legal = 000-840
tabblkcou.type = str
tabblkgrpce.legal = 0-9
tabblkgrpce.type = str
tabblkst.legal = 01-02,04-06,08-13,15-42,44-51,53-56,72
tabblkst.type = str
tables = Household Unit h1
tabtractce.legal = 000000-998999
tabtractce.type = str
ten.legal = 0-3
ten.type = int
tenvacgq = ten vacs qgqtyp
tenvacgq.legal = 0-34
tenvacgq.type = int
unit.class = programs.reader.cef_2020.cef_2020_dhch_reader.CEF2020DHCHUnitTable
unit.generated_module = programs.reader.cef_2020.cef_validator_classes
unit.generated_table = CEF20_UNIT
unit.geography = geocode
unit.histogram = tenvacgq
unit.path = ${DAS_S3INPUTS}/2010-convert/cef/us/unit
unit.recoder = programs.reader.cef_2020.cef_2020_dhch_reader.DHCH_Unit_recoder
unit.recode_variables = tenvacgq
unit.variables = MAFID ten vacs gqtype geocode
unit_table = Unit
vacs.legal = 0-7
vacs.type = int
validate_input_data_constraints = False

[schema]
schema = DHCH_SCHEMA

[setup]
environment = AWS_AUTO_SCALING_HOME,AWS_DEFAULT_REGION,AWS_CLOUDWATCH_HOME,AWS_ELB_HOME,AWS_PATH,BCC_HTTP_PROXY,BCC_HTTPS_PROXY,BCC_NO_PROXY,BOOTSTRAP_VERSION,CLUSTERID,DAS_ENVIRONMENT,DAS_ESB,DAS_LOGHOST,DAS_S3ROOT,DAS_SQS_URL,FRIENDLY_NAME,GIT_SSL_NO_VERIFY,GRB_APP_NAME,GRB_ISV_NAME,GRB_LICENSE_FILE,GUROBI_HOME,JBID,MASTER,MISSION_NAME,NO_PROXY,TEMP,TMPDIR,TZ
setup = programs.das_setup.DASDecennialSetup
spark.loglevel = ERROR
spark.name = DAS_RI_TEST

[stats]
heartbeat_frequency = 60
notify_gc_master = 0

[takedown]
delete_output = 0
takedown = programs.takedown.takedown

[validator]
results_fname = /mnt/tmp/WNS_results
validator = programs.stub_validator.validator

[writer]
certificate_name = A very precise data set
certificate_person1 = Some Human 
certificate_person2 = Some Human 
certificate_person3 = Some Human
certificate_suffix = .certificate.pdf
certificate_title = Certificate of Disclosure Avoidance
certificate_title1 = Novice Programmer
certificate_title2 = Supervisor
certificate_title3 = CED Authorizing Officer
classification_level = C_U_I//CENS - Title 13 protected data
keep_attrs = geocode, raw, syn
multiwriter_writers = DHCH2020_MDFRevisedColumnNames
num_parts = 0
output_datafile_name = MDF_UNIT
output_path = ${DAS_S3INPUTS}/users/$JBID/dhch_experiments/test_20220318
overwrite_flag = 0
produce_flag = 1
s3cat = 1
s3cat_prefix = .pickle
s3cat_suffix = .txt
s3cat_verbose = 0
s3_tags = NMF=1, TAGGED=1
save_git_commit = 1
stats_dir = ${DAS_S3ROOT}/rpc/upload
upload_logfile = 1
writer = programs.writer.multi_writer.MultiWriter
write_metadata = 1
