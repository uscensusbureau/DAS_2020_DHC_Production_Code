[DEFAULT]
# root specifies the root location for all files; testdir specifies ???; mode specifies ???
# For the demo, the root in the current directory
root: .
testdir: .
mode: 0
INCLUDE=default.ini

[spark]
# Whatever spark options you may have

[logging]
logfilename: DAS
loglevel: INFO
logfolder: logs

[ENVIRONMENT]
DAS_FRAMEWORK_VERSION: 0.0.1
GRB_ISV_NAME: Census
GRB_APP_NAME: DAS
GRB_Env3: 0
GRB_Env4:

[geodict]:
#smallest to largest (no spaces)
geolevel_names: Enumdist,County,State,National
#(largest geocode length to smallest, put 1 for top level) (no spaces)
geolevel_leng: 10,6,2,1

[setup]
setup: programs.das_setup.DASDecennialSetup

# Spark config stuff
spark.name: DAS_1940
#local[6] tells spark to run locally with 6 threads
#spark.master: local[9]
#Error , only writes to log if there is an error (INFO, DEBUG, )
spark.loglevel: Error

[reader]
;PersonData.class: programs.reader.spar_table.SparseHistogramTable
;UnitData.class: programs.reader.spar_table.UnitFromPersonRepartitioned
PersonData.class: programs.reader.sql_spar_table.SQLSparseHistogramTable
UnitData.class: programs.reader.spar_table.UnitFromPersonRepartitioned
numReaderPartitions: 50


[engine]
engine: programs.engine.topdown_engine.TopdownEngine
;check_budget: off
pool_measurements: on

# should we delete the true data after making DP measurments (1 for True or 0 for False)
delete_raw: 0

[schema]
schema: 1940

[budget]
#budget in topdown order (e.g. US, State, .... , Block)
epsilon_budget_total: 1

#budget in topdown order (e.g. US, State, .... , Block)
geolevel_budget_prop: 0.25,0.25,0.25,0.25



# DP queries to create, (or None) (total budget proporiton must add to 1.0)
DPqueries: hhgq, votingage * race, hispanic * citizen, detailed
queriesprop: 0.25, 0.25, 0.25,  0.25

[workload]
workload: WORKLOAD_1940

[constraints]
theInvariants.Enumdist: gqhh_vect,gqhh_tot
theInvariants.State: tot

theConstraints.Enumdist: hhgq_total_lb,hhgq_total_ub
theConstraints.State: total,hhgq_total_lb,hhgq_total_ub

minimalSchema: GQTYPE2


[writer]
output_path: ${DAS_S3INPUTS}/users/user007/tmp
output_datafile_name: data

#Write the Data? 0 or 1
produce_flag: 1
#keep_attrs: geocode, syn, raw_housing

#options for block_node_write
# delete existing file (if one) 0 or 1
overwrite_flag: 1

[validator]
validator: programs.stub_validator.validator
#validator: programs.stub_validator.validator
results_fname: /mnt/tmp/RA_results

[assessment]

[takedown]
takedown: programs.takedown.takedown
delete_output: True

[experiment]
run_experiment_flag: 0

[error_metrics]
error_metrics: programs.metrics.accuracy_metrics_workload.AccuracyMetricsWorkload
