# The 'main' 'testing' file, constantly used. This is the one you should use for "does it run" test
# This is used for jenkins.

[DEFAULT]
INCLUDE=default.ini
epsilon = 1

[gurobi]

record_gurobi_stats: True

# Gurobi prints stats to STDOUT on the CORE nodes, where it is hard to find..
# You probably don't want to do this.
print_gurobi_stats= False
;save_lp_path = $DAS_S3ROOT/lpfiles/$JBID/$MISSION_NAME
;save_lp_pattern = *

seq_optimization_approach =L2PlusRounder_interleaved
;l2_optimization_approach = DataIndUserSpecifiedQueriesNPass
l2_optimization_approach = SinglePassRegular
;rounder_optimization_approach = MultipassRounder
rounder_optimization_approach = CellWiseRounder
DataIndNPass_toleranceType = opt_tol
#const_tol_val = 25.0
opt_tol_slack = 0.1

[spark]
# Whatever spark options you may have
# not currently implemented

[logging]
logfilename= DAS
loglevel= INFO
logfolder= logs
dvs_enabled= False

[environment]
;these environment variables automatically created on the MASTER and CORE nodes.

DAS_FRAMEWORK_VERSION= 0.0.1
GRB_ISV_NAME= Census
GRB_APP_NAME= DAS
GRB_Env3= 0
GRB_Env4=

[geodict]
# smallest to largest (no spaces)
#geolevel_names=Block,Block_Group,Tract,County,State
#(largest geocode length to smallest, put 0 for US or US+PR (i.e. above state) level)

geolevel_leng= 16,12,11,5,2
#geo_bottomlevel = County
spine= opt_spine

# The first reccomendation from the Geography Division for the choice parameter aian_areas is:
aian_areas=Legal_Federally_Recognized_American_Indian_Area,American_Indian_Joint_Use_Area,Hawaiian_Home_Land,Alaska_Native_Village_Statistical_Area,State_Recognized_Legal_American_Indian_Area,Oklahoma_Tribal_Statistical_Area,Joint_Use_Oklahoma_Tribal_Statistical_Area

[setup]
setup= programs.das_setup.DASDecennialSetup
# Spark config stuff
spark.name= DAS_RI_TEST
#local[6] tells spark to run locally with 6 threads
#spark.master= local[9]
#Error , only writes to log if there is an error (INFO, DEBUG, ERROR)
spark.loglevel= ERROR

[reader]
PersonData.path= $DAS_S3INPUTS/title13_input_data/table8/ri44.txt
UnitData.path=   $DAS_S3INPUTS/title13_input_data/table8/ri44.txt
;reader= programs.reader.pickled_blocks_syn2raw_reader.PickledBlockSyn2RawReader
;pickled.path= $DAS_S3INPUTS/users/user007/temp/data
PersonData.class= programs.reader.sql_spar_table.SQLSparseHistogramTable
UnitData.class= programs.reader.sql_spar_table.UnitFromPersonSQLSparseHistogramTable

numReaderPartitions= 500
;measure_rdd_times= on
validate_input_data_constraints= off
partition_by_block_group= off
input_data_vintage = 2010

[engine]
engine= programs.engine.topdown_engine.TopdownEngine
repartition_optimized_node_rdd_evenly = True
part_size_noisy = 100

part_size_optimized = 100
part_size_optimized_block = 500

# Sparse
#saved_noisy_app_id= application_1564059690213_0341
# Same as np.array
#saved_noisy_app_id= application_1570048278175_0034
#saved_noisy_app_id= application_1609431813838_0794
#saved_optimized_app_id= application_1609431813838_0794
#optimization_start_from_level = Block

#Eps 1000
#saved_noisy_app_id= application_1580837820168_1294

# This one has saved optimized levels
;saved_noisy_app_id= application_1570048278175_0427
#postprocess_only= on
check_budget= off
;pool_measurements= on
;reload_noisy= off
save_noisy=on
;noisy_measurements_postfix= noisy_measurements
;spark= off
;return_all_levels= on
;reset_dpq_weights= on

# should we delete the true data after making DP measurements (1 for True or 0 for False)
delete_raw= 0

[schema]
schema= PL94

[budget]
privacy_framework= zcdp
dp_mechanism= discrete_gaussian_mechanism
print_per_attr_epsilons= True
global_scale= 1
state_numraces = 1/1024
#4472/10000
#epsilon_budget_total= 4/1


#budget in topdown order (e.g. US+PR, State, .... , Block)
geolevel_budget_prop= 103/512, 103/512, 102/512, 102/512, 102/512

strategy: test_strategy
query_ordering: test_strategy_regular_ordering

;[workload]
;workload= PL94, P1

[constraints]
#the invariants created, (no spaces)
theInvariants.Block= gqhh_vect, gqhh_tot
theInvariants.Tract= tot

#these are the info to build cenquery.constraint objects
theConstraints.Block= hhgq_total_lb, hhgq_total_ub, nurse_nva_0
theConstraints.Tract= total, hhgq_total_lb, hhgq_total_ub

minimalSchema= hhgq

[writer]
#writer= programs.writer.multi_writer.MultiWriter
#multiwriter_writers= BlockNodeDicts, MDFPersonAny
# Where the data gets written:
output_path= $DAS_S3ROOT/runs/test/$JBID/topdown_RI
output_datafile_name= data
produce_flag= 0
keep_attrs= geocode, syn, raw_housing
certificate_name = P.L. 94-171 Redistricting Data RI DevRun
certificate_person1 = Some Human
drb_clearance_number = CBDRB-FY20-DSEP-002

;noisy_partitions_by_level= 1000, 100, 10, 1, 0

# delete existing file (if one) 0 or 1
overwrite_flag= 1
save_git_commit= 1

# combine output into a single file
s3cat= 1
s3cat_suffix= .txt
s3cat_verbose= 1

# num_parts=0 turns writer .coalesce off. For large runs should be a few thousand, for PL94-RI-like tests, 100
num_parts= 0

[validator]
validator= programs.stub_validator.validator
#validator= programs.stub_validator.validator
results_fname= /mnt/tmp/RA_results

[assessment]

[takedown]
takedown= programs.takedown.takedown
delete_output= False

[experiment]
experiment= programs.experiment.config_loops_exp.ConfigLoopsExperimentByLevel
run_experiment_flag= 0
#loop1= FOR DEFAULT.run = 1 TO 1
loop2= FOR DEFAULT.epsilon IN 1,10,100
plotx = epsilon

[error_metrics]
#error_metrics= programs.metrics.accuracy_metrics_workload.AccuracyMetricsWorkload
error_metrics= programs.metrics.accuracy_metrics.AccuracyMetrics
calculate_binned_query_errors= False
calculate_per_query_quantile_errors= False
calculate_per_query_quantile_signed_errors= False
compute_prim_error_metrics = False
;print_place_mcd_ose_bg_l1_error_on_total_pop=False
;print_aians_l1_error_on_total_pop=False
;#print_block_and_county_total_pop_errors=False
;l1_relative_error_queries: cenrace_7lev_two_comb * hispanic, gqlevels
;print_blau_quintile_errors = False
;print_8_cell_cenrace_hisp_errors = True
;;population_cutoff: 500
;;l1_relative_error_geolevels: Place, Block_Group, OSE
;print_block_and_county_total_pop_errors=False
;#print_county_total_and_votingage = True
;skip_levels = Block, Block_Group
