# This is the configuration file to be used for the execution of PL94 for the US (not US+PR, i.e. excluding Puerto Rico)
# The only configuration information needed here is geolevel information and configuration of the input and output locations and names
# Most configuration information specific to PL94 is located in persons_default.ini


[DEFAULT]
;INCLUDE = person_default.ini
; begin include from person_default.ini
;INCLUDE = ../prod_default.ini

; end include from person_default.ini

[geodict]
#smallest to largest (no spaces)
geolevel_names = Block,Block_Group,Tract,County,State,US
#(largest geocode length to smallest, put 0 for US or US+PR (i.e. above state) level)
geolevel_leng = 16,12,11,5,2,0
target_das_aian_areas = True

;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
ignore_gqs_in_block_groups = False
;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
# Geolevel_names and geolevel_lengs are implemented in inherited files, as they are different for US and for PR
#smallest to largest (no spaces)
#geolevel_names = Block,Block_Group,Tract,Tract_Group,County,State,US
#(largest geocode length to smallest, put 0 for US or US+PR (i.e. above state) level)
#geolevel_leng = 16,14,11,8,5,2,0
geocode_length = 16
geo_toplevel =
geo_bottomlevel = Block
geo_path =

spine = opt_spine

# The first recommendation from the Geography Division for the choice parameter aian_areas is
aian_areas = Legal_Federally_Recognized_American_Indian_Area,
    American_Indian_Joint_Use_Area,
    Hawaiian_Home_Land,
    Alaska_Native_Village_Statistical_Area,
    State_Recognized_Legal_American_Indian_Area,
    Oklahoma_Tribal_Statistical_Area,
    Joint_Use_Oklahoma_Tribal_Statistical_Area

; end include from ../prod_default.ini
; end include from person_default.ini
[setup]
spark.name = PL94-nonneg-US

;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
setup = programs.das_setup.DASDecennialSetup
spark.loglevel = ERROR
environment = AWS_AUTO_SCALING_HOME,AWS_DEFAULT_REGION,AWS_CLOUDWATCH_HOME,AWS_ELB_HOME,AWS_PATH,BCC_HTTP_PROXY,BCC_HTTPS_PROXY,BCC_NO_PROXY,BOOTSTRAP_VERSION,CLUSTERID,DAS_ENVIRONMENT,DAS_ESB,DAS_LOGHOST,DAS_S3ROOT,FRIENDLY_NAME,GIT_SSL_NO_VERIFY,GRB_APP_NAME,GRB_ISV_NAME,GRB_LICENSE_FILE,GUROBI_HOME,JBID,MASTER,MISSION_NAME,NO_PROXY,TEMP,TMPDIR,TZ

; end include from ../prod_default.ini
; end include from person_default.ini
[reader]
input_data_vintage: 2010
numReaderPartitions = 10000
Person.path = ${DAS_S3INPUTS}/runs/experiments/cef/us/per/CEF20_PER_[0-9]*.txt
Unit.path =  ${DAS_S3INPUTS}/runs/experiments/cef/us/unit/CEF20_UNIT_[0-9]*.txt
grfc_path =  ${DAS_S3INPUTS}/runs/experiments/grfc/grfc_tab20_[0-9]*.txt

;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
tables = Unit Person
unit_table = Unit
main_table = Person

Person.class = programs.reader.cef_2020.cef_2020_dhcp_reader.CEF2020PersonsTable
Unit.class = programs.reader.cef_2020.cef_2020_dhcp_reader.CEF2020DHCPUnitTable

Person.generated_module = programs.reader.cef_2020.cef_validator_classes
Person.generated_table = CEF20_PER

Unit.generated_module = programs.reader.cef_2020.cef_validator_classes
Unit.generated_table = CEF20_UNIT

Person.histogram = hhgq votingage hispanic cenrace_das

Person.recoder = programs.reader.cef_2020.cef_2020_dhcp_reader.PL94_2020_recoder
Person.recode_variables = hhgq votingage hispanic cenrace_das

# variable_name= space delimited list of variables needed to do the recode
hhgq = qgqtyp
hhgq.type = int
hhgq.legal = 0-7

votingage = qage
votingage.type = int
votingage.legal = 0-1

hispanic = cenhisp
hispanic.type = int
hispanic.legal = 0-1

cenrace_das = cenrace
cenrace_das.type = int
cenrace_das.legal = 0-62

Unit.histogram = hhgq_unit_simple_recoded

Unit.recoder =  programs.reader.cef_2020.cef_2020_dhcp_reader.PL94_2020_Unit_recoder
Unit.recode_variables = hhgq_unit_simple_recoded

hhgq_unit_simple_recoded = qgqtyp
hhgq_unit_simple_recoded.type = int
hhgq_unit_simple_recoded.legal = 0-7

Person.geography = geocode
Unit.geography = geocode

;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
validate_input_data_constraints = True
readerPartitionLen = 14
reader = programs.reader.table_reader.DASDecennialReader
delimiter = \t
header = True

; end include from ../prod_default.ini
; end include from person_default.ini
[engine]
noisy_measurements_postfix = NMF10_PER_US
;optimization_start_from_level = Block
saved_optimized_app_id = application_1628779800498_0005
saved_noisy_app_id = application_1628779800498_0005
;postprocess_only = on

;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
;geolevel_num_part = 0,0,0,10000,4000,100,1
delete_raw = 0
save_noisy = 1
reload_noisy = 1
check_budget = off
engine = programs.engine.topdown_engine.TopdownEngine

; end include from ../prod_default.ini
; end include from person_default.ini
[budget]
#budget in topdown order (e.g. US, State, .... , Block)
global_scale = 339/542
geolevel_budget_prop = 104/4099, 1440/4099, 447/4099, 687/4099, 1256/4099, 165/4099
strategy = ProductionCandidate20210527US_mult8_add02_dsepJune3
query_ordering = Strategy1b_ST_CTY_TR_BG_isoTot_Ordering_dsepJune3

;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
# MWH Note 04/08: The intent is to take the final global_scale and set it here, so that this config can be used directly for production.
# Commented out currently to ensure it is getting the one in the sub-hierarchy for the PPMF.
; [SHADOWED] global_scale = 429/439

dp_mechanism =discrete_gaussian_mechanism

# The strategies are now different for US and PR (query allocation varies)
# strategy = Strategy1b_St_Cty_BG_optSpine_ppmfCandidate
; [SHADOWED] query_ordering = Strategy1b_ST_CTY_BG_isoTot_Ordering


;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
approx_dp_delta = 1e-10
only_dyadic_rationals = False
privacy_framework= zcdp
; [SHADOWED] dp_mechanism =discrete_gaussian_mechanism

print_per_attr_epsilons = True

; end include from ../prod_default.ini
; end include from person_default.ini
[writer]
output_path = $DAS_S3ROOT/runs/test/$JBID/PL94-nonneg-US
output_datafile_name = data

;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
multiwriter_writers = BlockNodeDicts, MDFPL942020

;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
stats_dir = $DAS_S3ROOT/rpc/upload
upload_logfile = 0
save_git_commit = 1

classification_level = C_U_I//SP-CENS - Title 13 protected data
produce_flag = 1

writer = programs.writer.multi_writer.MultiWriter
write_metadata = 1
s3cat = 1
s3cat_suffix = .txt
s3cat_verbose = 0
overwrite_flag = 1
num_parts = 10000
keep_attrs = geocode, syn, unit_syn, _invar, _cons, raw, raw_housing

# The certificate!
# It has the logfile name followed by certificate_suffix.
certificate_suffix = .certificate.pdf
certificate_name = P.L. 94-171 Redistricting Data {US Persons, US Units, PR Persons, PR Units}
certificate_title = Certificate of Disclosure Avoidance
certificate_person1 = Some Human 
certificate_title1 = Technical Operator
certificate_person2 = Some Human 
certificate_title2 = DAS Portfolio Manager
certificate_person3 = Some Human
certificate_title3 = CED Authorizing Officer

; end include from ../prod_default.ini
; end include from person_default.ini
[validator]
#validate_at_level = US,State,Block_Group,Block

;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
;validator = programs.validator.end2end_validator.E2EValidatorPL942020

;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
validator = programs.stub_validator.validator

; end include from ../prod_default.ini
; end include from person_default.ini
[constraints]
# Explicitly setting the State and US constraints here because they differ from PR
theConstraints.State = hhgq_total_lb, hhgq_total_ub
theConstraints.US = total

;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
#the invariants created, (no spaces)
theInvariants.Block = gqhh_vect, gqhh_tot
theInvariants.State = tot

theConstraints.Block = hhgq_total_lb, hhgq_total_ub, nurse_nva_0

# US and State constraints are different for US and PR, and are defined explicitly in person_US.ini and person_PR.ini

minimalSchema = hhgq

;INCLUDE=../prod_default.ini ; from [default]
; end include from person_default.ini
[error_metrics]
print_place_mcd_ose_bg_l1_error_on_total_pop=True
print_aians_l1_error_on_total_pop=True
#print_block_and_county_total_pop_errors=False
;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
l1_relative_error_queries: cenrace_7lev_two_comb * hispanic, gqlevels
print_blau_quintile_errors = True
print_8_cell_cenrace_hisp_errors = True


;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
#error_metrics = programs.metrics.error_metrics_stub.ErrorMetricsStub

population_cutoff: 500

error_metrics = programs.metrics.accuracy_metrics.AccuracyMetrics
calculate_binned_query_errors = True
calculate_per_query_quantile_errors = True
calculate_per_query_quantile_signed_errors = True
l1_relative_error_geolevels: Place, Block_Group, OSE

; end include from ../prod_default.ini
; end include from person_default.ini
[gurobi]
;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
l2_optimization_approach = DataIndUserSpecifiedQueriesNPass
rounder_optimization_approach = MultipassRounder
DataIndNPass_toleranceType = opt_tol
#const_tol_val = 25.0
opt_tol_slack = 0.1

seq_optimization_approach = L2PlusRounder_interleaved

;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
gurobi_path: $GUROBI_HOME/linux64/lib/${PYTHON_VERSION}_utf32/
gurobi_lic:  $GUROBI_HOME/gurobi_client.lic
gurobi_logfile_name: gurobi.log

gurobi_lic_create=true
TOKENSERVER=$GRB_TOKENSERVER
PORT=$GRB_TOKENSERVER_PORT

outputflag = 1

optimalitytol = 1e-6
barconvtol = 0.0
bariterlimit = 1000
feasibilitytol = 1e-7
presolve = -1
numericfocus = 3
method = -1
python_presolve = 1
record_gurobi_stats = True

# Control the number of threads used by Gurobi
threads = 96
# Threads for the top-geolevel
threads_root2root = 96
# Threads for each geolevel (if not top geolevel)
threads_state = 96
threads_county = 32
# Not used, commenting out
# threads_tract_group = 96
threads_tract = 16
threads_block_group = 8
threads_block = 4
l2_suboptimal_allowed = False
l2_grb_algorithm = -1
l2_grb_presolve = -1
l2_grb_presparsify = -1

L2_acceptable_statuses = OPTIMAL, SUBOPTIMAL, ITERATION_LIMIT
Rounder_acceptable_statuses = OPTIMAL

; end include from ../prod_default.ini
; end include from person_default.ini
[schema]
;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
schema = PL94_2020_SCHEMA

;INCLUDE=../prod_default.ini ; from [default]
; end include from person_default.ini
[logging]
;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
logfilename = DAS
loglevel = INFO
logfolder = logs

# DVS Configuration for the data vintaging system
dvs_enabled = 0
dvs_api_endpoint = https://{HOST_NAME}/api/dvs

; end include from ../prod_default.ini
; end include from person_default.ini
[ENVIRONMENT]
;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
das_framework_version = 1.1.0
grb_isv_name = Census
grb_app_name = DAS
grb_env3 = 0
grb_env4 =

; end include from ../prod_default.ini
; end include from person_default.ini
[takedown]
;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
takedown = programs.takedown.takedown
delete_output = 0

; end include from ../prod_default.ini
; end include from person_default.ini
[experiment]
;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
run_experiment_flag = 0

; end include from ../prod_default.ini
; end include from person_default.ini
[stats]
;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
heartbeat_frequency = 1
# Notify when GC is run on the master node
notify_gc_master = 0

; end include from ../prod_default.ini
; end include from person_default.ini
[monitoring]
;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
# Heartbeat just tells the user and the dashboard that we are alive
print_heartbeat = False
print_heartbeat_frequency = 180
send_stacktrace = False
heartbeat_frequency = 60

# Do we log to the dashboard on successful token acquisitions and retries?
# notifying that we got a token is just for debugging; this will typically be false
notify_dashboard_gurobi_success = false

# notifying that we had to retry is a problem; typically this will be true
notify_dashboard_gurobi_retry = true

# Notifications are about the current execution of the optimizer.
# It's collected from syslog.
notification_frequency = 60

; end include from ../prod_default.ini
; end include from person_default.ini
[alert]
;INCLUDE=person_default.ini ; from [default]
; begin include from person_default.ini
;INCLUDE=../prod_default.ini ; from [default]
; begin include from ../prod_default.ini
# Print this message when the system starts up
message = Hello world!
; end include from ../prod_default.ini
; end include from person_default.ini
