[logging]
logfilename = DAS
loglevel = INFO
logfolder = logs
dvs_enabled = False

[ENVIRONMENT]
das_framework_version = 0.0.1
grb_isv_name = Census
grb_app_name = DAS
grb_env3 = 0
grb_env4 =

[geodict]
# Geolevel_names and geolevel_lengs are implemented in inherited files, as they are different for US and for PR
#smallest to largest (no spaces)
#geolevel_names = Block,Block_Group,Tract,Tract_Group,County,State,US
#(largest geocode length to smallest, put 0 for US or US+PR (i.e. above state) level)
#geolevel_leng = 16,14,11,8,5,2,0
geocode_length = 16
geo_toplevel =
geo_bottomlevel =
geo_path =

# The first recommendation from the Geography Division for the choice parameter aian_areas is
aian_areas = Legal_Federally_Recognized_American_Indian_Area,
    American_Indian_Joint_Use_Area,
    Hawaiian_Home_Land,
    Alaska_Native_Village_Statistical_Area,
    State_Recognized_Legal_American_Indian_Area,
    Oklahoma_Tribal_Statistical_Area,
    Joint_Use_Oklahoma_Tribal_Statistical_Area


[setup]
setup = programs.das_setup.DASDecennialSetup
spark.loglevel = ERROR
environment = AWS_AUTO_SCALING_HOME,AWS_DEFAULT_REGION,AWS_CLOUDWATCH_HOME,AWS_ELB_HOME,AWS_PATH,BCC_HTTP_PROXY,BCC_HTTPS_PROXY,BCC_NO_PROXY,BOOTSTRAP_VERSION,MASTER_IP,CLUSTERID,DAS_ENVIRONMENT,DAS_ESB,DAS_LOGHOST,DAS_S3ROOT,DAS_S3INPUTS,DAS_CLOUD,DAS_RUN_TYPE,DAS_SQS_URL,DAS_SQS_ENDPOINT,DAS_DASHBOARD_URL,FRIENDLY_NAME,GIT_SSL_NO_VERIFY,GRB_APP_NAME,GRB_ISV_NAME,GRB_LICENSE_FILE,GUROBI_HOME,JBID,MASTER,MISSION_NAME,NO_PROXY,TEMP,TMPDIR,TZ,GRB_TOKENSERVER,GRB_TOKENSERVER_PORT

[reader]
validate_input_data_constraints: False
numReaderPartitions: 20000
readerPartitionLen: 14
reader = programs.reader.table_reader.DASDecennialReader
delimiter = \t
header = True

[engine]
;geolevel_num_part = 0,0,0,10000,4000,100,1
delete_raw = 0
save_noisy: 0
reload_noisy = 0
check_budget = off
engine = programs.engine.topdown_engine.TopdownEngine


[gurobi]
outputflag = 1
gurobi_path = /usr/local/lib64/python3.6/site-packages/gurobipy/linux64/lib/python3.6_utf32/
gurobi_lic = /usr/local/lib64/python3.6/site-packages/gurobipy/gurobi_client.lic
gurobi_logfile_name = gurobi.log
optimalitytol = 1e-4
barconvtol = 1e-8
barqcpconvtol = 0
bariterlimit = 1000
feasibilitytol = 1e-9
presolve = -1
numericfocus = 3
method = -1
python_presolve = 1
threads = 96
threads_root2root = 96
threads_state = 96
threads_county = 96
threads_tract_group = 96
threads_tract = 96
threads_block_group = 96
threads_block = 96
l2_suboptimal_allowed = False
l2_grb_algorithm = -1
l2_grb_presolve = -1
l2_grb_presparsify = -1

[writer]
stats_dir = $DAS_S3ROOT/rpc/upload
upload_logfile = 1
save_git_commit = 1

classification_level: C_U_I//CENS - Title 13 protected data
produce_flag = 1

writer: programs.writer.multi_writer.MultiWriter
write_metadata = 1
s3cat = 1
s3cat_suffix = .txt
s3cat_verbose = 0
overwrite_flag = 1
num_parts = 100
keep_attrs = geocode, syn, unit_syn
s3cat_prefix = .pickle

# the certificate!
# It has the logfile name followed by certificate_suffix.
certificate_suffix: .certificate.pdf
certificate_name: A very precise data set
certificate_title: Certificate of Disclosure Avoidance
certificate_person1: Some Human 
certificate_title1: Novice Programmer
certificate_person2: Some Human 
certificate_title2: Supervisor

[validator]
validator = programs.stub_validator.validator
results_fname = /mnt/tmp/WNS_results

[assessment]

[takedown]
takedown = programs.takedown.takedown
delete_output = 0

[experiment]
experiment = programs.experiment.experiment.experiment
run_experiment_flag = 0

[error_metrics]
error_metrics = programs.metrics.error_metrics_stub.ErrorMetricsStub

[stats]
heartbeat_frequency = 60
